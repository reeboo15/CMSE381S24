{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b646f43f-9920-4064-82ba-a6e8a98c4855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea4e497-5c86-4885-b97c-751c19ea88aa",
   "metadata": {},
   "source": [
    "## 3.7.10\n",
    "This question should be answered using the Carseats data set.\n",
    "\n",
    "(a) Fit a multiple regression model to predict Sales using Price, Urban, and US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0904615-46bb-4626-8427-2c9f2ebfdb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   41.52</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>2.39e-23</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:23:04</td>     <th>  Log-Likelihood:    </th> <td> -927.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   1863.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   396</td>      <th>  BIC:               </th> <td>   1879.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>    <td>   13.0435</td> <td>    0.651</td> <td>   20.036</td> <td> 0.000</td> <td>   11.764</td> <td>   14.323</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Urban[T.Yes]</th> <td>   -0.0219</td> <td>    0.272</td> <td>   -0.081</td> <td> 0.936</td> <td>   -0.556</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US[T.Yes]</th>    <td>    1.2006</td> <td>    0.259</td> <td>    4.635</td> <td> 0.000</td> <td>    0.691</td> <td>    1.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price</th>        <td>   -0.0545</td> <td>    0.005</td> <td>  -10.389</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.676</td> <th>  Durbin-Watson:     </th> <td>   1.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.713</td> <th>  Jarque-Bera (JB):  </th> <td>   0.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.093</td> <th>  Prob(JB):          </th> <td>   0.684</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.897</td> <th>  Cond. No.          </th> <td>    628.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.239\n",
       "Model:                            OLS   Adj. R-squared:                  0.234\n",
       "Method:                 Least Squares   F-statistic:                     41.52\n",
       "Date:                Wed, 07 Feb 2024   Prob (F-statistic):           2.39e-23\n",
       "Time:                        15:23:04   Log-Likelihood:                -927.66\n",
       "No. Observations:                 400   AIC:                             1863.\n",
       "Df Residuals:                     396   BIC:                             1879.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "================================================================================\n",
       "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------\n",
       "Intercept       13.0435      0.651     20.036      0.000      11.764      14.323\n",
       "Urban[T.Yes]    -0.0219      0.272     -0.081      0.936      -0.556       0.512\n",
       "US[T.Yes]        1.2006      0.259      4.635      0.000       0.691       1.710\n",
       "Price           -0.0545      0.005    -10.389      0.000      -0.065      -0.044\n",
       "==============================================================================\n",
       "Omnibus:                        0.676   Durbin-Watson:                   1.912\n",
       "Prob(Omnibus):                  0.713   Jarque-Bera (JB):                0.758\n",
       "Skew:                           0.093   Prob(JB):                        0.684\n",
       "Kurtosis:                       2.897   Cond. No.                         628.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "carseats_df = pd.read_csv(\"../DataSets/Carseats.csv\")\n",
    "mul_reg = smf.ols('Sales ~ Price + Urban + US', carseats_df).fit()\n",
    "mul_reg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3087c1-e2d9-4465-9065-06b70194c9b1",
   "metadata": {},
   "source": [
    "(b) Provide an interpretation of each coefficient in the model. Be careful—some of the variables in the model are qualitative!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eaf3c7-56b9-425d-9089-ae89bbe25c98",
   "metadata": {},
   "source": [
    "The coefficients are $\\beta_0 = 13.0435, \\beta_1 = -0.0219, \\beta_2 = 1.2006, \\beta_3 = -0.0545$. $\\beta_0$ is the intercept of the model, or the constant term. $\\beta_1$ is the value by which $\\beta_0$ increases if the carseat was sold in an urban area. $\\beta_2$ is the value by which $\\beta_0$ increases if the carseat was sold in the US. $\\beta_3$ is the value by which $\\beta_0$ increases if the price increases.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f4724f-0049-42eb-9337-12e5c01adc0a",
   "metadata": {},
   "source": [
    "(c) Write out the model in equation form, being careful to handle the qualitative variables properly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17f698-b05c-402c-8788-dd93f0877f41",
   "metadata": {},
   "source": [
    "Sales is represented as $Y$. \n",
    "$Y = 13.0435 + (-0.0219)*$ Urban[Yes] $+ (1.2006)*$US[Yes] $+ (-0.0545)*$ Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7826c9-053e-4513-948f-d1aec1629726",
   "metadata": {},
   "source": [
    "(d) For which of the predictors can you reject the null hypothesis $H_0 : \\beta_j = 0$?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7872d1f-6409-410b-9d18-a61ecc2e23f3",
   "metadata": {},
   "source": [
    "We can reject the Urban predictor because the p-value for this predictor is very high (>0.05). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05badba3-217c-4b32-9ddb-6affd0d4cc79",
   "metadata": {},
   "source": [
    "(e) On the basis of your response to the previous question, fit a smaller model that only uses the predictors for which there is evidence of association with the outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc119d6e-5792-4d1a-99df-00701755541b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.239</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   62.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 07 Feb 2024</td> <th>  Prob (F-statistic):</th> <td>2.66e-24</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:24:02</td>     <th>  Log-Likelihood:    </th> <td> -927.66</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   1861.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   1873.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   13.0308</td> <td>    0.631</td> <td>   20.652</td> <td> 0.000</td> <td>   11.790</td> <td>   14.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US[T.Yes]</th> <td>    1.1996</td> <td>    0.258</td> <td>    4.641</td> <td> 0.000</td> <td>    0.692</td> <td>    1.708</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price</th>     <td>   -0.0545</td> <td>    0.005</td> <td>  -10.416</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.044</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.666</td> <th>  Durbin-Watson:     </th> <td>   1.912</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.717</td> <th>  Jarque-Bera (JB):  </th> <td>   0.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.092</td> <th>  Prob(JB):          </th> <td>   0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.895</td> <th>  Cond. No.          </th> <td>    607.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.239\n",
       "Model:                            OLS   Adj. R-squared:                  0.235\n",
       "Method:                 Least Squares   F-statistic:                     62.43\n",
       "Date:                Wed, 07 Feb 2024   Prob (F-statistic):           2.66e-24\n",
       "Time:                        15:24:02   Log-Likelihood:                -927.66\n",
       "No. Observations:                 400   AIC:                             1861.\n",
       "Df Residuals:                     397   BIC:                             1873.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     13.0308      0.631     20.652      0.000      11.790      14.271\n",
       "US[T.Yes]      1.1996      0.258      4.641      0.000       0.692       1.708\n",
       "Price         -0.0545      0.005    -10.416      0.000      -0.065      -0.044\n",
       "==============================================================================\n",
       "Omnibus:                        0.666   Durbin-Watson:                   1.912\n",
       "Prob(Omnibus):                  0.717   Jarque-Bera (JB):                0.749\n",
       "Skew:                           0.092   Prob(JB):                        0.688\n",
       "Kurtosis:                       2.895   Cond. No.                         607.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul_reg_new = smf.ols('Sales ~ Price + US', carseats_df).fit()\n",
    "mul_reg_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd5b02-283b-4f6e-a015-322901bd1b38",
   "metadata": {},
   "source": [
    "## 4.8.4\n",
    "When the number of features p is large, there tends to be a deterioration in the performance of KNN and other local approaches that perform prediction using only observations that are near the test observation for which a prediction must be made. This phenomenon is known as the curse of dimensionality, and it ties into the fact that non-parametric approaches often perform poorly when p is large. We will now investigate this curse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b340e6f-48b6-485b-8807-f0891315c6e6",
   "metadata": {},
   "source": [
    "(a) Suppose that we have a set of observations, each with measurements on $p = 1$ feature, $X$. We assume that $X$ is uniformly (evenly) distributed on $[0, 1]$. Associated with each observation is a response value. Suppose that we wish to predict a test observation’s response using only observations that are within 10 % of the range of $X$ closest to that test observation. For instance, in order to predict the response for a test observation with $X = 0.6$, we will use observations in the range $[0.55, 0.65]$. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a38ea7-b990-480b-9c86-55ad2f7ce76e",
   "metadata": {},
   "source": [
    "We are using 10% of the range of the interval [0,1], therefore the fraction of available observations we will use is 10%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b02d38-2466-4b0c-b593-416362ece233",
   "metadata": {},
   "source": [
    "(b) Now suppose that we have a set of observations, each with\n",
    "measurements on $p = 2$ features, $X_1$ and $X_2$. We assume that $(X_1, X_2)$ are uniformly distributed on $[0, 1] \\times [0, 1]$. We wish to predict a test observation’s response using only observations that are within 10 % of the range of $X_1$ and within 10 % of the range of $X_2$ closest to that test observation. For instance, in order to predict the response for a test observation with $X_1 = 0.6$ and\n",
    "$X_2 = 0.35$, we will use observations in the range $[0.55, 0.65]$ for $X_1$ and in the range $[0.3, 0.4]$ for $X_2$. On average, what fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04fdf87-56ca-434a-92fc-795740290297",
   "metadata": {},
   "source": [
    "We use 10% of the first interval and 10% of the second interval, therefore in total we have 10% * 10%  = 1%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ebed83-96bb-4bb3-9016-b9710f08cfbe",
   "metadata": {},
   "source": [
    "(c) Now suppose that we have a set of observations on $p = 100$ features. Again the observations are uniformly distributed on each feature, and again each feature ranges in value from 0 to 1. We wish to predict a test observation’s response using observations within the 10 % of each feature’s range that is closest to that test observation. What fraction of the available observations will we use to make the prediction?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14940a50-bf41-43a8-b292-075e70fb1388",
   "metadata": {},
   "source": [
    "Using the same method from (b), we have that (0.1)^100 is the fraction of the available observations to be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6528091-8429-4062-bd74-5544ca1c3e8b",
   "metadata": {},
   "source": [
    "(d) Using your answers to parts (a)–(c), argue that a drawback of KNN when $p$ is large is that there are very few training observations “near” any given test observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe42da4-1079-4299-a3c8-8ae090acbcf3",
   "metadata": {},
   "source": [
    "When p is large we see that very little of the total set of observation is near any given test observation. As dimensions get larger (so p value gets larger) the number of of nearby neighbors goes to 0, therefore at a high enough dimension there are no neighbors in high dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d867c5d-56db-47e1-8d68-c81b4721022d",
   "metadata": {},
   "source": [
    "## 4.8.6\n",
    "\n",
    "Suppose we collect data for a group of students in a statistics class with variables $X_1 =$ hours studied, $X_2 =$ undergrad GPA, and $Y =$ receive an A. We fit a logistic regression and produce estimated coefficient, $\\hat{\\beta_0} = -6, \\hat{\\beta_1} = 0.05, \\hat{\\beta_2} = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d1ad9-928d-4109-a237-3dcefda94ff7",
   "metadata": {},
   "source": [
    "(a) Estimate the probability that a student who studies for 40 h and has an undergrad GPA of 3.5 gets an A in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eeaa5fa8-8526-432c-85e7-a92b0001de92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37754066879814546"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = -6 + 0.05*40 + 1*3.5\n",
    "y = np.exp(model) / (1+np.exp(model))\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f5e056-a213-4591-be5a-12883924a5a8",
   "metadata": {},
   "source": [
    "(b) How many hours would the student in part (a) need to study to have a 50 % chance of getting an A in the class?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab59753a-d0cb-4ce1-b0c7-1ce5fc32c2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have that 0.5 = e^model/(1+e^model)\n",
    "#so 0.5 + 0.5e^model = e^model\n",
    "#0.5e^model = 0.5\n",
    "#e^model = 0.5\n",
    "#model = 0\n",
    "#so we want to find values of hours and GPA such that 0.05*hours + GPA = 6\n",
    "#A is a 3.5\n",
    "#0.05*h = 6 - 3.5\n",
    "#h = (6-3.5)/0.05\n",
    "hours = (6-3.5)/0.05\n",
    "hours"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
