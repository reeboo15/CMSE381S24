{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dfd68f5",
   "metadata": {},
   "source": [
    "# Lecture 13 - PCR and PLS\n",
    "## CMSE 381 - SS 2024\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea3a4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everyone's favorite standard imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "# ML imports we've used previously\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7d5aa",
   "metadata": {},
   "source": [
    "# 1. PCA on Penguins\n",
    "![Palmer Penguins Picture](https://allisonhorst.github.io/palmerpenguins/reference/figures/lter_penguins.png)\n",
    "\n",
    "*Artwork by @allison_horst*\n",
    "\n",
    "\n",
    "For this lab, we are going to again use the <a href = \"https://allisonhorst.github.io/palmerpenguins/\">Palmer Penguins</a> data set by Allison Horst, Alison Hill, and Kristen Gorman. You should have done this in a previous notebook, but if you don't have the package installed to get the data, you can run \n",
    "```\n",
    "pip install palmerpenguins\n",
    "```\n",
    "to have access to the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd59457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from palmerpenguins import load_penguins\n",
    "penguins = load_penguins()\n",
    "penguins = penguins.dropna()\n",
    "\n",
    "#Shuffle the data\n",
    "#penguins = penguins.sample(frac=1)\n",
    "penguins.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32626ac",
   "metadata": {},
   "source": [
    "Before we get to the full version, let's just take a look at two of the columns: flipper length and bill length. A nice thing we can do is to also color the data by the species label. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12e5a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x = penguins.bill_length_mm, \n",
    "                y = penguins.flipper_length_mm, \n",
    "                hue = penguins.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53271b9",
   "metadata": {},
   "source": [
    "Before we get to it, we're going to just work with the columns that are numeric.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513fbbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_num = penguins.select_dtypes(np.number)\n",
    "penguins_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc78df3c",
   "metadata": {},
   "source": [
    "We normalize the data to make the visualization easier (meaning shifting our data to have mean 0 in every column, and have standard deviation 1). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e545b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_normalized = (penguins_num - penguins_num.mean())/penguins_num.std()\n",
    "p_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32336ff1",
   "metadata": {},
   "source": [
    "## PCA with just two input columns\n",
    "\n",
    "To try to draw pictures similar to what we just saw on the slides, we'll first focus on two of the columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ab810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_subset2 = p_normalized[['bill_length_mm', 'flipper_length_mm']]\n",
    "penguins_subset2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ae24ad",
   "metadata": {},
   "source": [
    "We run PCA using the `PCA` command from `scikitlearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c282c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PCA object\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Fit it using our data\n",
    "pca.fit(penguins_subset2.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995232dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pca.fit_transform(penguins_subset2.values)\n",
    "plt.scatter(pca_df[:,0], pca_df[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588432ac",
   "metadata": {},
   "source": [
    "The `pca.components_` store information about the lines we are going to project our data onto. Specifically, each row gives us one of these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c51d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22f7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = penguins_subset2, \n",
    "                x = 'bill_length_mm', \n",
    "                y = 'flipper_length_mm', \n",
    "                hue = penguins.species)\n",
    "\n",
    "for i, comp in enumerate(pca.components_):\n",
    "    slope = comp[1]/comp[0]\n",
    "    plt.plot(np.array([-2,2]), slope*np.array([-2,2]))\n",
    "    \n",
    "plt.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062b0cca",
   "metadata": {},
   "source": [
    "A common way to look at the relative importance of the PC's is to draw these components as vectors with length based on the explained variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc13489",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd942cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = penguins_subset2, \n",
    "                x = 'bill_length_mm', \n",
    "                y = 'flipper_length_mm', \n",
    "                hue = penguins.species)\n",
    "\n",
    "for i, (comp, var) in enumerate(zip(pca.components_, pca.explained_variance_)):\n",
    "    slope = comp[1]/comp[0]\n",
    "    plt.plot(np.array([-2,2]), slope*np.array([-2,2]))\n",
    "    \n",
    "    comp = comp * var  # scale component by its variance explanation power\n",
    "    plt.plot(\n",
    "        [0, comp[0]],\n",
    "        [0, comp[1]],\n",
    "        label=f\"Component {i}\",\n",
    "        linewidth=5,\n",
    "        color=f\"C{i + 2}\",\n",
    "    )\n",
    "\n",
    "plt.axis('square')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18823506",
   "metadata": {},
   "source": [
    "The next important part are the PC's, which we can get from the `pca` object as follows. I'm going to put them in a dataframe to make drawing and visualization easier. Basically, $PC_1$ is our $Z_1$ in the slides, and $PC_2$ is the $Z_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8899e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transform function takes in bill,flipper data points, \n",
    "# and returns a PC1,PC2 coordinate for each one. \n",
    "penguins_pca = pca.fit_transform(penguins_subset2)\n",
    "penguins_pca = pd.DataFrame(data = penguins_pca, columns = ['PC1', 'PC2'])\n",
    "penguins_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d0e0f",
   "metadata": {},
   "source": [
    "This is the scatterplot of the data points transformed into the PC space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be185a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data = penguins_pca, x = 'PC1', y = 'PC2',hue = penguins.species)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89914557",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** What are the PC scores for the first data point (index 0)?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132bd47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535149ec",
   "metadata": {},
   "source": [
    "## Penguins PCA with all columns\n",
    "\n",
    "We used only two columns above for visualization, but we can instead use all the input columns to run our PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbd8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "penguins_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c84f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=4)\n",
    "penguins_pca_all = pca.fit_transform(penguins_num)\n",
    "penguins_pca_all = pd.DataFrame(data = penguins_pca_all, \n",
    "                                columns = ['PC1', 'PC2', 'PC3', 'PC4'])\n",
    "penguins_pca_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57f44c9",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** Make a scatter plot of PC1 and PC2 using this new model, and again color the points by `penguins.species`. What do you notice about how the PC plot has changed from the previous setting? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b0c245",
   "metadata": {},
   "source": [
    "# Principal Component Regression \n",
    "\n",
    "Ok, let's take a hard left turn and go try out some of the dimension reduction methods from Section 6.3. `Scikit-learn` doesn't have a built in function to do PCR (aka PCA and then regression) but it's just as easy for us to do it ourselves. \n",
    "\n",
    "PCR is a supervised learning problem, so unlike PCA, it requires the exitence of the response variable. \n",
    "\n",
    "Let us shift gear and try to predict ``flipper_length`` from the rest of the numerical variables \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faeaa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = penguins['flipper_length_mm']\n",
    "X = penguins_num.drop(columns=['flipper_length_mm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe7c33",
   "metadata": {},
   "source": [
    "For the new dataframe `X`, let us calculate its PCs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2552e6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(X_pca.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1e9c79",
   "metadata": {},
   "source": [
    "From the output of the above cell, we see that just doing PCA does not automatically reduce the number of predictors. We actually have to manually reduce the predictors by picking how many PCs we want to use in the regression. Now, say we want to reduce the number of predictors from 4 to 3, then I would use only the first 3 PCs for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7c2332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "regr = LinearRegression()\n",
    "regr.fit(X_pca[:,:3], y)\n",
    "mean_squared_error(y,regr.predict(X_pca[:,:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24225df",
   "metadata": {},
   "source": [
    "&#9989; **<font color=red>Do this:</font>** My code above contains the rookie mistake of only reporting training error. Write modified code to return the 10-fold CV error of linear regression on the first 3 PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16c967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here #\n",
    "\n",
    "\n",
    "\n",
    "# You'll probably want this....\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505362e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
